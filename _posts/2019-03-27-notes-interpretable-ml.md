---
layout: post
title: Notes for Interpretable Machine Learning
date: 2017-08-25
categories: ML
description: ...
---


原文链接: [christophm.github.io](<https://christophm.github.io/interpretable-ml-book/>)

<br>

实现可解释机器学习模型有两种基本方式：

1. 使用可解释模型（Interpretable Models）。如线性模型或决策树
2. Model-Agnostic 解释方法。可以应用于任何监督学习模型

### Interpretability

可以从以下几个方面考虑 ML 的可解释性

- 算法如何训练产生模型？
- 模型如何做出预测？
- 模型的每个部分对预测会产生什么影响？
- 为什么对于特定一个输入会产生特定的输出？
- 为什么对于特定一组输入会产生特定的输出？

### 可解释性模型

#### 线性回归

- 基本公式：$$ y=w_1x_1 + w_2x_2 + … + w_mx_m + b$$
- 从模型组成成分解释：
  - 数值特征：其他特征保持不变的前提下，一个单位的数值特征 $x_k$ 改变给结果带来的改变是该特征对应的 weight $$w_k$​$
  - 二值特征：二值特征的改变给结果带来的改变是该特征对应的 weight
  - 分类特征：对分类特征进行 one-hot 编码，假设该类共有 L 类，对应需要 L-1 维编码特征，每维都是二值特征，对结果的影响参见二值特征
  - 截距 $$b​$$：当所有特征取值为 0 时，模型的预测为截距 $$b​$$

- 从 R-square 解释：
  - R 方是一个可以对模型进行一定解释的指标，表示**模型解释了多少 target 值中存在的方差**。其值约接近 1 表明模型拟合优度高
  - Note：随着自变量维度的增加 R 方会增加，可以使用调整 R 方抵消自变量维度增加的影响

- 从特征重要度解释：

  - 使用 t-检验 度量特征重要度 $$t_{w_{i}} = \frac{\hat{w_{i}}}{\sigma_{w_i}}$$
  - 上述式子的意义是：参数值越大对应特征越重要；参数值方差越大，特征重要度越小（特征不稳定）




<br>
